name: Log Analysis & Improvement Suggestions

on:
  schedule:
    # Run every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:
    inputs:
      hours_to_analyze:
        description: 'Hours of logs to analyze'
        required: false
        default: '4'

jobs:
  analyze-logs:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup SSH
        env:
          SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
          EC2_HOST: ${{ secrets.EC2_HOST }}
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_KEY" > ~/.ssh/fff-key.pem
          chmod 600 ~/.ssh/fff-key.pem
          ssh-keyscan -H "$EC2_HOST" >> ~/.ssh/known_hosts 2>/dev/null || true

      - name: Collect logs from EC2
        id: collect-logs
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ec2-user
          HOURS_INPUT: ${{ github.event.inputs.hours_to_analyze }}
        run: |
          HOURS="${HOURS_INPUT:-4}"

          # Collect logs from the last N hours
          ssh -i ~/.ssh/fff-key.pem -o StrictHostKeyChecking=no \
            "$EC2_USER@$EC2_HOST" \
            "sudo journalctl -u funding-fee-farmer --since '${HOURS} hours ago' --no-pager 2>/dev/null | tail -500" \
            > /tmp/recent_logs.txt || true

          # Also get current service status
          ssh -i ~/.ssh/fff-key.pem -o StrictHostKeyChecking=no \
            "$EC2_USER@$EC2_HOST" \
            "sudo systemctl status funding-fee-farmer --no-pager 2>/dev/null | head -20" \
            > /tmp/service_status.txt || true

          # Count errors and warnings (handle grep returning 1 when no matches)
          ERROR_COUNT="$(grep -c -E 'ERROR|âŒ' /tmp/recent_logs.txt 2>/dev/null)" || ERROR_COUNT="0"
          WARN_COUNT="$(grep -c -E 'WARN|âš ' /tmp/recent_logs.txt 2>/dev/null)" || WARN_COUNT="0"

          # Write outputs
          {
            echo "error_count=${ERROR_COUNT}"
            echo "warn_count=${WARN_COUNT}"
            echo "hours=${HOURS}"
          } >> "$GITHUB_OUTPUT"

      - name: Prepare analysis prompt
        id: prepare-prompt
        run: |
          # Read logs
          SERVICE_STATUS=$(cat /tmp/service_status.txt | head -50)
          RECENT_LOGS=$(cat /tmp/recent_logs.txt | tail -400)

          # Build prompt content and save to file for the action
          cat > /tmp/analysis_prompt.txt << PROMPT_EOF
          Analyze these funding fee farmer bot logs and identify potential improvements.

          ## Service Status
          \`\`\`
          ${SERVICE_STATUS}
          \`\`\`

          ## Recent Logs
          \`\`\`
          ${RECENT_LOGS}
          \`\`\`

          Please analyze and provide:
          1. **Health Assessment**: Is the bot running correctly? Any critical issues?
          2. **Error Analysis**: What errors occurred and their likely root causes?
          3. **Performance Observations**: Any patterns in timing, API calls, or resource usage?
          4. **Improvement Suggestions**: Specific code improvements that could be made

          For each improvement suggestion, rate it:
          - Priority: HIGH/MEDIUM/LOW
          - Effort: SMALL/MEDIUM/LARGE
          - Impact: Brief description of the benefit

          Format your response as JSON with this structure:
          \`\`\`json
          {
            "health_status": "healthy|degraded|critical",
            "summary": "Brief overall summary",
            "errors": [{"message": "...", "count": 1, "cause": "...", "fix": "..."}],
            "improvements": [
              {
                "title": "Short title for GitHub issue",
                "description": "Detailed description",
                "priority": "HIGH|MEDIUM|LOW",
                "effort": "SMALL|MEDIUM|LARGE",
                "impact": "What this improves",
                "files_to_modify": ["src/file.rs"],
                "suggested_approach": "How to implement this"
              }
            ]
          }
          \`\`\`
          PROMPT_EOF

          # Store prompt in output using delimiter for multiline
          echo "prompt<<PROMPT_DELIMITER" >> "$GITHUB_OUTPUT"
          cat /tmp/analysis_prompt.txt >> "$GITHUB_OUTPUT"
          echo "PROMPT_DELIMITER" >> "$GITHUB_OUTPUT"

      - name: Analyze logs with Claude API
        id: analyze
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          # Build the prompt
          PROMPT=$(cat /tmp/analysis_prompt.txt)

          # Call Claude API directly
          RESPONSE=$(curl -s https://api.anthropic.com/v1/messages \
            -H "Content-Type: application/json" \
            -H "x-api-key: $ANTHROPIC_API_KEY" \
            -H "anthropic-version: 2023-06-01" \
            -d "$(jq -n \
              --arg prompt "$PROMPT" \
              '{
                model: "claude-sonnet-4-20250514",
                max_tokens: 4096,
                messages: [{role: "user", content: $prompt}]
              }')")

          # Extract the text content from the response
          ANALYSIS=$(echo "$RESPONSE" | jq -r '.content[0].text // empty')

          if [ -z "$ANALYSIS" ]; then
            echo "API call failed or returned empty response"
            echo "Response: $RESPONSE"
            echo '{"health_status": "unknown", "summary": "API call failed", "errors": [], "improvements": []}' > /tmp/analysis_result.txt
          else
            echo "Analysis received (${#ANALYSIS} chars)"
            echo "$ANALYSIS" > /tmp/analysis_result.txt
          fi

      - name: Parse analysis and create issues
        uses: actions/github-script@v7
        env:
          ERROR_COUNT: ${{ steps.collect-logs.outputs.error_count }}
          WARN_COUNT: ${{ steps.collect-logs.outputs.warn_count }}
        with:
          script: |
            const fs = require('fs');
            const analysisOutput = fs.readFileSync('/tmp/analysis_result.txt', 'utf8');

            console.log('Raw analysis output length:', analysisOutput.length);
            console.log('First 500 chars:', analysisOutput.substring(0, 500));

            // Try multiple patterns to extract JSON from the response
            let analysis;
            const jsonPatterns = [
              /```json\s*([\s\S]*?)\s*```/,           // Standard markdown JSON block
              /```\s*([\s\S]*?)\s*```/,               // Any code block
              /\{[\s\S]*"health_status"[\s\S]*\}/,    // Raw JSON object with health_status
              /\{[\s\S]*"improvements"[\s\S]*\}/,     // Raw JSON object with improvements
            ];

            let jsonStr = null;
            for (const pattern of jsonPatterns) {
              const match = analysisOutput.match(pattern);
              if (match) {
                jsonStr = match[1] || match[0];
                console.log('Matched pattern:', pattern.toString().substring(0, 30));
                break;
              }
            }

            try {
              if (jsonStr) {
                // Clean up the JSON string
                jsonStr = jsonStr.trim();
                analysis = JSON.parse(jsonStr);
                console.log('Successfully parsed JSON');
              } else {
                // Try parsing the whole output as JSON
                analysis = JSON.parse(analysisOutput.trim());
              }
            } catch (e) {
              console.log('JSON parse error:', e.message);

              // Check if we should skip creating an issue (no critical problems)
              const errorCount = parseInt(process.env.ERROR_COUNT) || 0;
              const warnCount = parseInt(process.env.WARN_COUNT) || 0;

              // If no errors and few warnings, the bot is healthy - don't create noise
              if (errorCount === 0 && warnCount < 50) {
                console.log('Bot appears healthy (0 errors, few warnings). Skipping issue creation.');
                return;
              }

              // Create issue with the actual analysis text for review
              const today = new Date().toISOString().split('T')[0];
              const truncatedAnalysis = analysisOutput.length > 3000
                ? analysisOutput.substring(0, 3000) + '\n\n... (truncated)'
                : analysisOutput;

              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `[Log Analysis] Review needed - ${today}`,
                body: `## Automated Log Analysis\n\n**Errors**: ${errorCount}\n**Warnings**: ${warnCount}\n\n### Claude's Analysis\n\n${truncatedAnalysis}\n\n---\n*JSON parsing failed. Please review the analysis above.*`,
                labels: ['log-analysis', 'needs-review']
              });
              return;
            }

            // Log summary first
            console.log(`Health: ${analysis.health_status}`);
            console.log(`Summary: ${analysis.summary}`);
            console.log(`Errors found: ${(analysis.errors || []).length}`);
            console.log(`Improvements identified: ${(analysis.improvements || []).length}`);

            // Helper to check for existing issues
            async function issueExists(labelFilter, titleSubstring) {
              const existingIssues = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                labels: labelFilter
              });
              return existingIssues.data.some(issue => issue.title.includes(titleSubstring));
            }

            // CRITICAL/DEGRADED health status - create urgent issue
            if (analysis.health_status === 'critical' || analysis.health_status === 'degraded') {
              const exists = await issueExists('urgent', analysis.health_status);
              if (!exists) {
                const errorsSection = (analysis.errors || [])
                  .map(e => `- **${e.message}** (${e.count}x)\n  - Cause: ${e.cause}\n  - Fix: ${e.fix}`)
                  .join('\n') || 'No specific errors identified';

                await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: `ðŸš¨ [URGENT] Bot health ${analysis.health_status.toUpperCase()}`,
                  body: [
                    `## Health Status: ${analysis.health_status.toUpperCase()}`,
                    '',
                    `**Summary**: ${analysis.summary}`,
                    '',
                    '### Errors',
                    errorsSection,
                    '',
                    '---',
                    '*This issue was automatically created due to abnormal bot behavior.*',
                    '',
                    '@claude please investigate and fix this issue urgently.'
                  ].join('\n'),
                  labels: ['urgent', 'automated', analysis.health_status]
                });
                console.log(`Created urgent issue for ${analysis.health_status} health`);
              }
            }

            // Create issues for HIGH priority improvements
            const highPriorityImprovements = (analysis.improvements || [])
              .filter(i => i.priority === 'HIGH');

            for (const improvement of highPriorityImprovements) {
              const titlePrefix = improvement.title.substring(0, 30);
              const exists = await issueExists('claude-improvement', titlePrefix);

              if (!exists) {
                const filesSection = (improvement.files_to_modify || [])
                  .map(f => `- \`${f}\``)
                  .join('\n') || '- TBD';

                await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: `[Auto] ${improvement.title}`,
                  body: [
                    '## Automated Improvement Suggestion',
                    '',
                    `**Priority**: ${improvement.priority}`,
                    `**Effort**: ${improvement.effort}`,
                    `**Impact**: ${improvement.impact}`,
                    '',
                    '### Description',
                    improvement.description,
                    '',
                    '### Files to Modify',
                    filesSection,
                    '',
                    '### Suggested Approach',
                    improvement.suggested_approach,
                    '',
                    '---',
                    '*This issue was automatically created by log analysis.*',
                    '',
                    '@claude please implement this improvement.'
                  ].join('\n'),
                  labels: ['claude-improvement', 'automated', improvement.priority.toLowerCase()]
                });
                console.log(`Created issue: ${improvement.title}`);
              } else {
                console.log(`Skipping duplicate: ${improvement.title}`);
              }
            }

            // If healthy with no issues, close any stale "Review needed" issues
            if (analysis.health_status === 'healthy' && (analysis.errors || []).length === 0) {
              const staleIssues = await github.rest.issues.listForRepo({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                labels: 'needs-review'
              });

              for (const issue of staleIssues.data) {
                if (issue.title.includes('[Log Analysis] Review needed')) {
                  await github.rest.issues.update({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issue.number,
                    state: 'closed',
                    state_reason: 'completed'
                  });
                  console.log(`Closed stale issue #${issue.number}: ${issue.title}`);
                }
              }
            }

      - name: Cleanup
        if: always()
        run: |
          rm -f ~/.ssh/fff-key.pem
          rm -f /tmp/recent_logs.txt /tmp/service_status.txt
          rm -f /tmp/analysis_prompt.txt /tmp/analysis_result.txt
